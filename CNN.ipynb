{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, ask_to_proceed_with_overwrite\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras.layers import SimpleRNN, LSTM,  GRU,SeparableConvolution2D, Conv2D\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.applications import VGG16, VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Activation, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "def getModel( output_dim ):\n",
    "    ''' \n",
    "        * output_dim: the number of classes (int)\n",
    "        \n",
    "        * return: compiled model (keras.engine.training.Model)\n",
    "    '''\n",
    "    #vgg_model = VGG16( weights='imagenet', include_top=False )\n",
    "    vgg_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in vgg_model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = vgg_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(output_dim ,activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "    model = Model(input=vgg_model.input, output=predictions)\n",
    "\n",
    "    #Freeze all layers of VGG16 and Compile the model\n",
    "    #Confirm the model is appropriate\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(weights_path, output_dim):\n",
    "\n",
    "    model = getModel( output_dim ) \n",
    "#     for k,layer in model.layers_by_depth.items()[1:]:\n",
    "#         layer[0].trainable = False\n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'categorical_crossentropy'])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(N,output_dim):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    \n",
    "    filenames = sorted(glob.glob(\"/Users/francescoferrari/Downloads/logo_dataset_6/*/*.jpg\"))\n",
    "    \n",
    "    junk_filenames = glob.glob(\"/Users/francescoferrari/Downloads/junk_processed/*/*.jpg\")\n",
    "    \n",
    "    random.shuffle(junk_filenames)\n",
    "    \n",
    "    junk_filenames = junk_filenames[:len(filenames)]\n",
    "    filenames += junk_filenames\n",
    "    \n",
    "    random.shuffle(filenames)\n",
    "    X_mean = 0.0\n",
    "    for filename in filenames[:N]:\n",
    "        label = np.zeros(output_dim,)\n",
    "        idx = labels_dict.get(filename.split(\"/\")[2], 6)\n",
    "        label[idx] = 1.0\n",
    "        img = np.asarray(Image.open(filename).resize((224, 224), Image.ANTIALIAS))/255.\n",
    "        if img.shape == (224,224,3):\n",
    "            X_mean += img.mean()\n",
    "            y.append(label)\n",
    "            X.append(img)\n",
    "\n",
    "        \n",
    "    limit = int(len(X)/10*8)\n",
    "    print(len(X))\n",
    "    print(limit)\n",
    "    X_mean = X_mean/float(len(X))\n",
    "    X_train = np.array(X[:limit])\n",
    "    X_val = np.array(X[limit:])\n",
    "    y_train = np.array(y[:limit])\n",
    "    y_val = np.array(y[limit:])   \n",
    "    X_train -= X_mean\n",
    "    X_val -= X_mean\n",
    "    print(\"completed formatting!\")\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_dict = {\"Cocacola\":0, \"LOreal\":1,\"LouisVuitton\":2,\"Nike\":3,\"Pepsi\":4,\"Samsung\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2820\n",
      "2256\n",
      "completed formatting!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = load_data(100000,7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  '` call to the Keras 2 API: ' + signature)\n"
     ]
    }
   ],
   "source": [
    "output_dim = 7\n",
    "epochs = 100\n",
    "#model = getModel( output_dim ) \n",
    "\n",
    "model = load_model(\"weights-improvement-VGG16-LOGO7-08-0.7677.hdf5\",7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-VGG16-LOGO7-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor='val_acc', patience=4, verbose=0, mode='auto')\n",
    "callbacks_list = [earlyStopping, checkpoint]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy', 'categorical_crossentropy'])\n",
    "\n",
    "\n",
    "h = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "          batch_size=16, nb_epoch=epochs, verbose=1,callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2256, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
